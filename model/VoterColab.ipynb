{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VoterColab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMVs7AApf23f",
        "outputId": "a16522dc-7ead-40a1-b102-50be4d5ea2af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -rf /content/vanGogh-and-Other-Artist\n",
        "#!git clone https://github.com/czkaiweb/vanGogh-and-Other-Artist.git\n",
        "\n",
        "# To fetch the change from git repo\n",
        "%cd /content/vanGogh-and-Other-Artist\n",
        "!git fetch \n",
        "!git pull\n",
        "#!git checkout develop\n",
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3w7ciVsvf6_l",
        "outputId": "62e88434-baa8-4a20-e7d5-cbbaa5bfe133"
      },
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/vanGogh-and-Other-Artist\n",
            "remote: Enumerating objects: 7, done.\u001b[K\n",
            "remote: Counting objects: 100% (7/7), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 4 (delta 3), reused 4 (delta 3), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (4/4), done.\n",
            "From https://github.com/czkaiweb/vanGogh-and-Other-Artist\n",
            "   edb85ec..84df172  develop    -> origin/develop\n",
            "Updating edb85ec..84df172\n",
            "Fast-forward\n",
            " model/genericVoter.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/vanGogh-and-Other-Artist')\n",
        "sys.path.append('/content/vanGogh-and-Other-Artist/preprocessing')\n",
        "sys.path.append('/content/vanGogh-and-Other-Artist/model')\n",
        "from genericVoter import *\n",
        "from preprocessing.ImageTranform import *\n",
        "from torchsummary import summary\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy\n",
        "from tqdm import tqdm\n",
        "import hashlib\n",
        "\n",
        "from torchvision import datasets, models, transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler"
      ],
      "metadata": {
        "id": "V2EzHowMgKSc"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C4QMzgJgThm",
        "outputId": "22d99a23-ae0d-4015-9020-b8c41570f0cd"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Meta record\n",
        "fileList = []\n",
        "img_path = \"./imgs\"\n",
        "\n",
        "if not os.path.isdir(img_path):\n",
        "    os.mkdir(img_path)"
      ],
      "metadata": {
        "id": "r8UAR-e5gYCk"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_path = \"/root/.kaggle\"\n",
        "if not os.path.isdir(kaggle_path):\n",
        "  os.mkdir(kaggle_path)"
      ],
      "metadata": {
        "id": "tker_qICgX_7"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "fkQc2PB4gX9S"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download van Gogh dataset\n",
        "!kaggle datasets download -d ipythonx/van-gogh-paintings\n",
        "\n",
        "# List all von Goph plots\n",
        "tmp_path = \"./tmp\"\n",
        "vangoghZip = 'van-gogh-paintings.zip'\n",
        "try:\n",
        "    shutil.unpack_archive(vangoghZip,tmp_path)\n",
        "except Exception as err:\n",
        "    print(err)\n",
        "\n",
        "allVanGogh = glob.glob(tmp_path+'/*/*.jpg')\n",
        "\n",
        "# Append metadata\n",
        "for index in tqdm(range(len(allVanGogh))):\n",
        "    fileName = allVanGogh[index]\n",
        "    file = fileName.split(\"/\")[-1]\n",
        "    hashName = hashlib.md5(file.encode()).hexdigest()\n",
        "    shutil.move(fileName, img_path + \"/\" + hashName + \".jpg\", copy_function = shutil.copy2)\n",
        "    artist = \"vanGogh\"\n",
        "    fileList.append([hashName,artist])\n",
        "    \n",
        "# Clean tmp data\n",
        "try:\n",
        "    shutil.rmtree(tmp_path)\n",
        "    os.remove(vangoghZip)\n",
        "except Exception as err:\n",
        "    print(err)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMak1wpBgX6c",
        "outputId": "6d586cf5-7e5d-46b1-cac2-a62d42ed93d9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading van-gogh-paintings.zip to /content\n",
            " 99% 481M/485M [00:09<00:00, 77.1MB/s]\n",
            "100% 485M/485M [00:09<00:00, 54.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2024/2024 [00:00<00:00, 33054.05it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d srrrrr/monet2photo\n",
        "\n",
        "# List all Monet plots\n",
        "tmp_path = \"./tmp\"\n",
        "monetZip = 'monet2photo.zip'\n",
        "try:\n",
        "    shutil.unpack_archive(monetZip,tmp_path)\n",
        "except Exception as err:\n",
        "    print(err)\n",
        "\n",
        "allMonet = glob.glob(tmp_path+'/*/trainA/*.jpg')\n",
        "\n",
        "# Append metadata\n",
        "for index in tqdm(range(len(allMonet))):\n",
        "    fileName = allMonet[index]\n",
        "    file = fileName.split(\"/\")[-1]\n",
        "    hashName = hashlib.md5(file.encode()).hexdigest()\n",
        "    shutil.move(fileName, img_path + \"/\" + hashName + \".jpg\", copy_function = shutil.copy2)\n",
        "    artist = \"Monet\"\n",
        "    fileList.append([hashName,artist])\n",
        "    \n",
        "# Clean tmp data\n",
        "try:\n",
        "    shutil.rmtree(tmp_path)\n",
        "    os.remove(monetZip)\n",
        "except Exception as err:\n",
        "    print(err)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgdhAdyrgX2n",
        "outputId": "0f25b492-014f-4946-8271-6a6584d0d6f0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading monet2photo.zip to /content\n",
            " 96% 253M/263M [00:03<00:00, 123MB/s]\n",
            "100% 263M/263M [00:03<00:00, 83.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1072/1072 [00:00<00:00, 35258.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download WikiArts dataset: https://www.kaggle.com/datasets/antoinegruson/-wikiart-all-images-120k-link\n",
        "!kaggle datasets download -d czkaiweb/subwikiarts\n",
        "\n",
        "# List all wikiarts plots\n",
        "tmp_path = \"./tmp\"\n",
        "wikiartsZip = 'subwikiarts.zip'\n",
        "try:\n",
        "    shutil.unpack_archive(wikiartsZip,tmp_path)\n",
        "except Exception as err:\n",
        "    print(err)\n",
        "\n",
        "WikiArtsMeta = tmp_path+\"/WikiArts.csv\"\n",
        "WikiArtsDF = pd.read_csv(WikiArtsMeta)\n",
        "WikiArtsList = WikiArtsDF[[\"hash\",\"Artist\"]].values\n",
        "\n",
        "def findGroup(head):\n",
        "    if head <= \"33\":\n",
        "        return \"/GroupA/\"\n",
        "    elif head <= \"69\":\n",
        "        return \"/GroupB/\"\n",
        "    elif head <= \"9d\":\n",
        "        return \"/GroupC/\"\n",
        "    elif head <= \"cc\":\n",
        "        return \"/GroupD/\"\n",
        "    else:\n",
        "        return \"/GroupE/\"\n",
        "    \n",
        "# Set to true for group splitting\n",
        "preClean = False\n",
        "if preClean == True:\n",
        "    for char in [\"A\",\"B\",\"C\",\"D\",\"E\"]:\n",
        "        groupDir = img_path+\"/Group{}\".format(char)\n",
        "        if not os.path.isdir(groupDir):\n",
        "            os.mkdir(groupDir)\n",
        "\n",
        "for record in WikiArtsList:\n",
        "    groupDir = \"/./\"\n",
        "    if preClean:\n",
        "        groupDir = findGroup(record[0][:2])\n",
        "    fileName = tmp_path+\"/imgs/\"+record[0]+\".jpg\"\n",
        "    shutil.move(fileName, img_path+ groupDir + \"/\" , copy_function = shutil.copy2)\n",
        "    \n",
        "# Clean tmp data\n",
        "try:\n",
        "    shutil.rmtree(tmp_path)\n",
        "    os.remove(wikiartsZip)\n",
        "except Exception as err:\n",
        "    print(err)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ODWEJ2SgX0M",
        "outputId": "e45482df-8209-4f1c-ffb4-a1d75de29322"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading subwikiarts.zip to /content\n",
            "100% 993M/995M [00:11<00:00, 118MB/s]\n",
            "100% 995M/995M [00:11<00:00, 92.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to meta file\n",
        "metaDF = pd.DataFrame(fileList,columns = [\"hash\",\"Artist\"])\n",
        "metaDF = pd.concat([metaDF,WikiArtsDF[[\"hash\",\"Artist\"]]])\n",
        "metaDF.to_csv(\"meta.csv\")"
      ],
      "metadata": {
        "id": "fkALy9GzgXyL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myVoter = genericVoter()"
      ],
      "metadata": {
        "id": "1U9ESS0OgXvy"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "listTransformer = []\n",
        "listModel = []\n",
        "listWeight = []\n",
        "\n",
        "# For vgg16\n",
        "myTransform = ImageTransformer((224,224))\n",
        "myTransform.initTransform()\n",
        "transformer = myTransform.getTransformer()\n",
        "listTransformer.append(transformer)\n",
        "\n",
        "model_vgg = models.vgg16()\n",
        "num_ftrs = model_vgg.classifier[6].in_features\n",
        "model_vgg.classifier[6] = nn.Linear(num_ftrs, 6)\n",
        "model_vgg = model_vgg.to(myVoter.device)\n",
        "model_vgg.load_state_dict(torch.load('/content/drive/MyDrive/VGG16_weights_May28.pth'))\n",
        "listModel.append(model_vgg)\n",
        "\n",
        "listWeight.append('/content/drive/MyDrive/VGG16_weights_May28.pth')\n",
        "\n",
        "# For EfficientNet\n",
        "myTransform = ImageTransformer((224,224))\n",
        "myTransform.initTransform()\n",
        "transformer = myTransform.getTransformer()\n",
        "listTransformer.append(transformer)\n",
        "\n",
        "model_effnet = models.efficientnet_b0()\n",
        "num_ftrs = model_effnet.classifier[1].in_features\n",
        "model_effnet.classifier[1] = nn.Linear(num_ftrs, 6)\n",
        "model_effnet = model_effnet.to(myVoter.device)\n",
        "model_effnet.load_state_dict(torch.load('/content/drive/MyDrive/model_weights_EfficientNetB0_final.pth'))\n",
        "listModel.append(model_effnet)\n",
        "\n",
        "listWeight.append('/content/drive/MyDrive/model_weights_EfficientNetB0_final.pth')\n",
        "\n",
        "# For MobileNet_v2\n",
        "myTransform = ImageTransformer((224,224))\n",
        "myTransform.initTransform()\n",
        "transformer = myTransform.getTransformer()\n",
        "listTransformer.append(transformer)\n",
        "\n",
        "model_mobnet = models.mobilenet_v2()\n",
        "num_ftrs = model_mobnet.classifier[1].in_features\n",
        "model_mobnet.classifier[1] = nn.Linear(num_ftrs, 6)\n",
        "model_mobnet = model_mobnet.to(myVoter.device)\n",
        "model_mobnet.load_state_dict(torch.load('/content/drive/MyDrive/model_weights_mobilenet_v2_valp1trainp2.pth'))\n",
        "listModel.append(model_mobnet)\n",
        "\n",
        "listWeight.append('/content/drive/MyDrive/model_weights_mobilenet_v2_valp1trainp2.pth')\n",
        "\n",
        "# For ResNet\n",
        "myTransform = ImageTransformer((224,224))\n",
        "myTransform.initTransform()\n",
        "transformer = myTransform.getTransformer()\n",
        "listTransformer.append(transformer)\n",
        "\n",
        "model_resnet = models.resnet34()\n",
        "num_ftrs = model_resnet.fc.in_features\n",
        "model_resnet.fc = nn.Linear(num_ftrs, 6)\n",
        "model_resnet = model_resnet.to(myVoter.device)\n",
        "listModel.append(model_resnet)\n",
        "\n",
        "listWeight.append('/content/drive/MyDrive/model_weights_resnet34.pth')\n",
        "\n",
        "myVoter.setBagging(listModel,listTransformer,listWeight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7neCPGIgXtD",
        "outputId": "f74103d2-7234-47f2-aec5-0e60e1e4623b"
      },
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:1421: UserWarning: The parameter 'resample' is deprecated since 0.12 and will be removed in 0.14. Please use 'interpolation' instead.\n",
            "  \"The parameter 'resample' is deprecated since 0.12 and will be removed in 0.14. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:1436: UserWarning: The parameter 'fillcolor' is deprecated since 0.12 and will be removed in 0.14. Please use 'fill' instead.\n",
            "  \"The parameter 'fillcolor' is deprecated since 0.12 and will be removed in 0.14. \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "myTransform = ImageTransformer((224,224))\n",
        "myTransform.initTransform()\n",
        "transformer = myTransform.getTransformer()\n",
        "myVoter.setTransformer(transformer)\n",
        "\n",
        "# Set up the meta data and path to image dataset\n",
        "myVoter.setDataset(\"meta.csv\",path = \"imgs\")\n",
        "\n",
        "# Split the data by portion, fraction indicate the percentage of data used in the whole dataset. \n",
        "# Default: val_size = 0.2, test_size = 0.1 \n",
        "myVoter.splitData(val_size=0.1,test_size = 0.7,fraction = 1)\n",
        "\n",
        "# Will automatically get the statistic for training set, update the mean/std used for normalization. \n",
        "# loadData and checkDataset\n",
        "myVoter.loadData()\n",
        "myVoter.checkDataset()\n",
        "myVoter.trainMean = torch.tensor([0.5396, 0.4863, 0.4146])\n",
        "myVoter.trainStd = torch.tensor([0.2776, 0.2715, 0.2588])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ-2bi2YgXqV",
        "outputId": "02ca96e1-d892-43b4-9f9a-701a3141b401"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:1421: UserWarning: The parameter 'resample' is deprecated since 0.12 and will be removed in 0.14. Please use 'interpolation' instead.\n",
            "  \"The parameter 'resample' is deprecated since 0.12 and will be removed in 0.14. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:1436: UserWarning: The parameter 'fillcolor' is deprecated since 0.12 and will be removed in 0.14. Please use 'fill' instead.\n",
            "  \"The parameter 'fillcolor' is deprecated since 0.12 and will be removed in 0.14. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53e872e09c40a912e36d53daf6920243 torch.Size([4, 224, 224])\n",
            "0641ceb25ff823cf52802ea8c07558b1 torch.Size([1, 224, 224])\n",
            "ee7c58e67dabd4b7459bddf9f669f707 torch.Size([1, 224, 224])\n",
            "84e717a6cf749d681ffbb2557758bd13 torch.Size([1, 224, 224])\n",
            "7dc6002a966d35a49f263376c2a56256 torch.Size([1, 224, 224])\n",
            "8c9f5633d217a54f78ed5f2146324b38 torch.Size([1, 224, 224])\n",
            "632fc73d4e2de07f28d85429ff390476 torch.Size([1, 224, 224])\n",
            "b96a4a83299a54b4be4ff78c0d92c170 torch.Size([1, 224, 224])\n",
            "a2bbef5813e42924f2168bef12a26478 torch.Size([4, 224, 224])\n",
            "9d694f7ee70d5f694dda849a0a132bcb torch.Size([4, 224, 224])\n",
            "d7999f4ec0a7efcc004c733e813ddb39 torch.Size([4, 224, 224])\n",
            "0be2cd049d2ecf361c6ffcb1c5054de5 torch.Size([4, 224, 224])\n",
            "e2ee5d0fd45f95074b7e5e8665ab22de torch.Size([4, 224, 224])\n",
            "bcbf898f298ba2a00e088c50e3e27134 torch.Size([1, 224, 224])\n",
            "e5f0411ee34ba439116a0d8d8cfe64c3 torch.Size([1, 224, 224])\n",
            "042faaee15402a071df98949a2fe4298 torch.Size([1, 224, 224])\n",
            "521cde1dc6bf903b92698cce5fc45cc9 torch.Size([1, 224, 224])\n",
            "19527a307f8328d218c0d592b0e62eb9 torch.Size([1, 224, 224])\n",
            "04e84f850d81a2e0a7440e13b46744e4 torch.Size([1, 224, 224])\n",
            "66855fd1af6fcc7eb4ed461d5c82a810 torch.Size([1, 224, 224])\n",
            "f5ef2960e0f5227289fb2e126ce0b4c5 torch.Size([1, 224, 224])\n",
            "a2e7131ada2d8c94340e87dde1fbee69 torch.Size([1, 224, 224])\n",
            "c9250c6bebf980301c38dc5735024fba torch.Size([1, 224, 224])\n",
            "db1d700c1a5c2bd9fdede96e65032757 torch.Size([1, 224, 224])\n",
            "b808f9e26122a39d1f22814ca8f21db6 torch.Size([1, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "myVoter.prepareInputForVoter(skipNorm = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HI8fxUfgXns",
        "outputId": "9210917f-2b1b-4720-fd8d-fb3286e79903"
      },
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 565/565 [00:20<00:00, 27.52it/s]\n",
            "100%|██████████| 565/565 [00:20<00:00, 26.91it/s]\n",
            "100%|██████████| 565/565 [00:18<00:00, 30.63it/s]\n",
            "100%|██████████| 565/565 [00:18<00:00, 29.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sanity check for model:0, accuracy:0.8707964601769912\n",
            "Sanity check for model:1, accuracy:0.9061946902654867\n",
            "Sanity check for model:2, accuracy:0.8548672566371681\n",
            "Sanity check for model:3, accuracy:0.8407079646017699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn import svm\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "voters = {\n",
        "#    \"xgboost\"  : xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42),\n",
        "    \"kNeighbor\" : KNeighborsClassifier(3),\n",
        "    \"svm_rbf\"  : svm.SVC(kernel='rbf', gamma=0.5, C=0.1),\n",
        "    \"svm_poly\" : svm.SVC(kernel='poly', degree=3, C=1),\n",
        "    \"randomForest\": RandomForestClassifier(n_estimators=5, random_state=1),\n",
        "    \"decisionTree\" :  DecisionTreeClassifier(max_depth=3),\n",
        "    #\"Logistic\": LogisticRegression(multi_class='multinomial',random_state=1)\n",
        "}\n",
        "\n",
        "myVoter.highaccuracy = None\n",
        "myVoter.bestVoter = None\n",
        "myVoter.setVoterClassifier(voters)\n",
        "myVoter.fitVoter(useKFold=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L0NxUt7zgXK0",
        "outputId": "d9c1f6e2-13d6-48b2-c838-3be618711685"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kNeighbor accuracy: 0.9203539823008849\n",
            "svm_rbf accuracy: 0.863716814159292\n",
            "svm_poly accuracy: 0.7132743362831858\n",
            "randomForest accuracy: 0.9415929203539823\n",
            "decisionTree accuracy: 0.8035398230088495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#myVoter.bestVoter.predict([[1,1,3]])\n",
        "myVoter.evaluateVoter()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm-hJP4wqIvk",
        "outputId": "34ab9321-afd9-4e59-9a05-7385426e0990"
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3952/3952 [05:09<00:00, 12.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "voter accuracy: 0.888917004048583\n",
            "base model: 0 accu: 0.8307186234817814\n",
            "base model: 1 accu: 0.8833502024291497\n",
            "base model: 2 accu: 0.8656376518218624\n",
            "hard voting accu: 0.895495951417004\n"
          ]
        }
      ]
    }
  ]
}