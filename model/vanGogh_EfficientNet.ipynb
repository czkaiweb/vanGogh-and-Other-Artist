{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"vanGogh_EfficientNetB2.ipynb","provenance":[{"file_id":"https://github.com/czkaiweb/vanGogh-and-Other-Artist/blob/main/model/TemplateOnColab.ipynb","timestamp":1653635194980}],"collapsed_sections":[],"private_outputs":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Van Gogh and other artist\n","This notebook is dedicated for running generic pipeline on Colab, kaggle token is required for dataset download."],"metadata":{"id":"EgIOtxM-QcLr"}},{"cell_type":"markdown","source":["1. Clone the repository to your colab area:"],"metadata":{"id":"X3588jMxQz8P"}},{"cell_type":"code","source":["!git clone https://github.com/czkaiweb/vanGogh-and-Other-Artist.git\n","\n","# To fetch the change from git repo\n","%cd /content/vanGogh-and-Other-Artist\n","!git fetch \n","!git pull\n","#!git checkout develop\n","%cd /content\n","\n"],"metadata":{"id":"xsCgcXl6fjph"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2. Import the files and needed packages:"],"metadata":{"id":"XX7GoO1wQ8Dx"}},{"cell_type":"code","source":["import sys\n","sys.path.append('/content/vanGogh-and-Other-Artist')\n","sys.path.append('/content/vanGogh-and-Other-Artist/preprocessing')\n","sys.path.append('/content/vanGogh-and-Other-Artist/model')\n","from genericCNN import *\n","from preprocessing.ImageTranform import *\n","from torchsummary import summary\n","\n","import shutil\n","import os\n","import glob\n","import pandas as pd\n","import numpy\n","from tqdm import tqdm\n","import hashlib\n","\n","from torchvision import datasets, models, transforms\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","\n","%load_ext autoreload\n","%autoreload 2"],"metadata":{"id":"d7ayire6f7mx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3.Create image output folder:"],"metadata":{"id":"avn1vIupRUVr"}},{"cell_type":"code","source":["# Create Meta record\n","fileList = []\n","img_path = \"./imgs\"\n","\n","if not os.path.isdir(img_path):\n","    os.mkdir(img_path)"],"metadata":{"id":"cBhWWC_KgEQv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4. Setup Kaggle token file:"],"metadata":{"id":"og1ei-hNRiTK"}},{"cell_type":"code","source":["kaggle_path = \"/root/.kaggle\"\n","if not os.path.isdir(kaggle_path):\n","  os.mkdir(kaggle_path)\n"],"metadata":{"id":"8hIrcAHyRtMk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["5. In the left column, click \"File\", go to parent folder, check if  /root/.kaggle is existed. Upload your kaggle token file (usually it is named kaggle.json) there.\n","Using \"chmod\" to set proper authentication to protect your token"],"metadata":{"id":"F1axlj5XSCNI"}},{"cell_type":"code","source":["!chmod 600 /root/.kaggle/kaggle.json"],"metadata":{"id":"aIvWNui5Sm62"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[""],"metadata":{"id":"kKMmH9PjuVzA"}},{"cell_type":"markdown","source":["6. Download the van gogh dataset, unzip the dataset and append the meta data:"],"metadata":{"id":"Qshqp9_0Tn6r"}},{"cell_type":"code","source":["# Download van Gogh dataset\n","!kaggle datasets download -d ipythonx/van-gogh-paintings\n","\n","# List all von Goph plots\n","tmp_path = \"./tmp\"\n","vangoghZip = 'van-gogh-paintings.zip'\n","try:\n","    shutil.unpack_archive(vangoghZip,tmp_path)\n","except Exception as err:\n","    print(err)\n","\n","allVanGogh = glob.glob(tmp_path+'/*/*.jpg')\n","\n","# Append metadata\n","for index in tqdm(range(len(allVanGogh))):\n","    fileName = allVanGogh[index]\n","    file = fileName.split(\"/\")[-1]\n","    hashName = hashlib.md5(file.encode()).hexdigest()\n","    shutil.move(fileName, img_path + \"/\" + hashName + \".jpg\", copy_function = shutil.copy2)\n","    artist = \"vanGogh\"\n","    fileList.append([hashName,artist])\n","    \n","# Clean tmp data\n","try:\n","    shutil.rmtree(tmp_path)\n","    os.remove(vangoghZip)\n","except Exception as err:\n","    print(err)"],"metadata":{"id":"OGCJK5WYgome"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["7. Download the monet dataset, unzip the dataset and append the meta data:"],"metadata":{"id":"NHIvm5sMTykj"}},{"cell_type":"code","source":["!kaggle datasets download -d srrrrr/monet2photo\n","\n","# List all Monet plots\n","tmp_path = \"./tmp\"\n","monetZip = 'monet2photo.zip'\n","try:\n","    shutil.unpack_archive(monetZip,tmp_path)\n","except Exception as err:\n","    print(err)\n","\n","allMonet = glob.glob(tmp_path+'/*/trainA/*.jpg')\n","\n","# Append metadata\n","for index in tqdm(range(len(allMonet))):\n","    fileName = allMonet[index]\n","    file = fileName.split(\"/\")[-1]\n","    hashName = hashlib.md5(file.encode()).hexdigest()\n","    shutil.move(fileName, img_path + \"/\" + hashName + \".jpg\", copy_function = shutil.copy2)\n","    artist = \"Monet\"\n","    fileList.append([hashName,artist])\n","    \n","# Clean tmp data\n","try:\n","    shutil.rmtree(tmp_path)\n","    os.remove(monetZip)\n","except Exception as err:\n","    print(err)"],"metadata":{"id":"wN-3LZkTg2NE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["8. Download the customized dataset, unzip the dataset and append the meta data:"],"metadata":{"id":"eWlTGizgT2cv"}},{"cell_type":"code","source":["# Download WikiArts dataset: https://www.kaggle.com/datasets/antoinegruson/-wikiart-all-images-120k-link\n","!kaggle datasets download -d czkaiweb/subwikiarts\n","\n","# List all wikiarts plots\n","tmp_path = \"./tmp\"\n","wikiartsZip = 'subwikiarts.zip'\n","try:\n","    shutil.unpack_archive(wikiartsZip,tmp_path)\n","except Exception as err:\n","    print(err)\n","\n","WikiArtsMeta = tmp_path+\"/WikiArts.csv\"\n","WikiArtsDF = pd.read_csv(WikiArtsMeta)\n","WikiArtsList = WikiArtsDF[[\"hash\",\"Artist\"]].values\n","\n","def findGroup(head):\n","    if head <= \"33\":\n","        return \"/GroupA/\"\n","    elif head <= \"69\":\n","        return \"/GroupB/\"\n","    elif head <= \"9d\":\n","        return \"/GroupC/\"\n","    elif head <= \"cc\":\n","        return \"/GroupD/\"\n","    else:\n","        return \"/GroupE/\"\n","    \n","# Set to true for group splitting\n","preClean = False\n","if preClean == True:\n","    for char in [\"A\",\"B\",\"C\",\"D\",\"E\"]:\n","        groupDir = img_path+\"/Group{}\".format(char)\n","        if not os.path.isdir(groupDir):\n","            os.mkdir(groupDir)\n","\n","for record in WikiArtsList:\n","    groupDir = \"/./\"\n","    if preClean:\n","        groupDir = findGroup(record[0][:2])\n","    fileName = tmp_path+\"/imgs/\"+record[0]+\".jpg\"\n","    shutil.move(fileName, img_path+ groupDir + \"/\" , copy_function = shutil.copy2)\n","    \n","# Clean tmp data\n","try:\n","    shutil.rmtree(tmp_path)\n","    os.remove(wikiartsZip)\n","except Exception as err:\n","    print(err)\n"],"metadata":{"id":"szespjoEiVzx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["9. Create the csv file for meta data:"],"metadata":{"id":"pfpLcB-dUNDH"}},{"cell_type":"code","source":["# Save to meta file\n","metaDF = pd.DataFrame(fileList,columns = [\"hash\",\"Artist\"])\n","metaDF = pd.concat([metaDF,WikiArtsDF[[\"hash\",\"Artist\"]]])\n","metaDF.to_csv(\"meta.csv\")"],"metadata":{"id":"4SIjhsNfifEk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["10. Import the generic pipeline and transformer if not imported yet, set the image transformer to the genericCNN"],"metadata":{"id":"9HcwxKvHUV_Q"}},{"cell_type":"code","source":["#Initialize the object\n","myObj = genericCNN()\n","\n","# Set up the transformer\n","myTransform = ImageTransformer((224,224))\n","myTransform.initTransform()\n","transformer = myTransform.getTransformer()\n","\n","myObj.setTransformer(transformer)\n","# Decide if adding normalization layer at the end of transformation, by default, normalization will be added\n","# myObj.UseNormalized(normalize = True)"],"metadata":{"id":"oFbIgI3hixOO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["11. Set meta data and input path, split the dataset and load the data to Dataset/DatasetLoader"],"metadata":{"id":"n3GlIBk4upW-"}},{"cell_type":"code","source":["# Set up the meta data and path to image dataset\n","myObj.setDataset(\"meta.csv\",path = \"imgs\")\n","\n","# Split the data by portion, fraction indicate the percentage of data used in the whole dataset. \n","# Default: val_size = 0.2, test_size = 0.1 \n","#myObj.splitData(val_size=0.05,test_size = 0.8,fraction = 1)\n","#myObj.splitData(val_size=0.2,test_size = 0.1,fraction = 1)\n","myObj.splitData(val_size=0.1,test_size = 0.7,fraction = 1)\n","\n","# Will automatically get the statistic for training set, update the mean/std used for normalization. \n","# loadData and checkDataset\n","myObj.loadData(reUseTrain=3)\n","#myObj.loadData()"],"metadata":{"id":"efiy4r6Yi2K5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["12. Display a batch:"],"metadata":{"id":"TVYeFs_Bu4WW"}},{"cell_type":"code","source":["myObj.showDatasetBatch()"],"metadata":{"id":"JZlU_0Wnjqkj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["13. Select model and edit the architecture:"],"metadata":{"id":"LUxaI7XL70B6"}},{"cell_type":"code","source":["# Use the pre-trained model\n","#model_ft = models.vgg16(pretrained=True)\n","#model_ft = models.efficientnet_b2(pretrained=True)\n","model_ft = models.efficientnet_b0(pretrained=True)\n","#model_ft.load_state_dict(torch.load('./weights/vgg16-397923af.pth'))\n","num_ftrs = model_ft.classifier[1].in_features\n","model_ft.classifier[1] = nn.Linear(num_ftrs, 6)\n","model_ft = model_ft.to(myObj.device)\n","\n","# Specifiy the criterion:\n","criterion = nn.CrossEntropyLoss()\n","\n","# Specify the optizimer\n","optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n","\n","# Specift the learning rate scheduler. Decay LR by a factor of 0.1 every 7 epochs\n","exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"],"metadata":{"id":"oM4og4enj6u5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["14. Set the model for the generic object:"],"metadata":{"id":"sbIJ_frw-fvD"}},{"cell_type":"code","source":["#myObj.setModel(model = model_ft,modeltag=\"EfficientNetB2mod\")\n","myObj.setModel(model = model_ft,modeltag=\"EfficientNetB0mod\")"],"metadata":{"id":"eWfVZrjXkgKd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["15: Train the model:"],"metadata":{"id":"I9KJFGZX-mJe"}},{"cell_type":"code","source":["myObj.train_model(criterion, optimizer_ft, exp_lr_scheduler, num_epochs=13)\n","#myObj.evaluate()\n","#myObj.drawHistory()"],"metadata":{"id":"aAnlTRShkr16"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["16. Evaluate the model:"],"metadata":{"id":"vXikESZ3XzHb"}},{"cell_type":"code","source":["myObj.evaluate()"],"metadata":{"id":"sXo03Y6m6upY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["myObj.drawHistory()"],"metadata":{"id":"7qhxBsdmZF5r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["17. Save the weights as pth file:"],"metadata":{"id":"iOnv7ZmP-sTe"}},{"cell_type":"code","source":["torch.save(myObj.Model.state_dict(), 'model_weights_EfficientNetB0_newTrainTestSplits_13epochs_001lr_9momentum.pth')"],"metadata":{"id":"4lsDvSD1kwp9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["18. Download the weight file from colab:"],"metadata":{"id":"XIEEDXeI7vzQ"}},{"cell_type":"code","source":["from google.colab import files\n","files.download(\"model_weights_EfficientNetB0_newTrainTestSplits_13epochs_001lr_9momentum.pth\")"],"metadata":{"id":"7nTzVCRVlIjk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"t7cxQO8BYafP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.scatter(np.arange(1,22,1), myObj.trainAccu)\n","plt.scatter(np.arange(1,22,1), myObj.valAccu, c=\"orange\")\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend(['Train', 'Val'])\n","plt.title('Train/Val Accuracy Vs Epoch For EfficientNetB2')"],"metadata":{"id":"ZL3KtmNmc-L0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"9nQmPAjqxxU0"},"execution_count":null,"outputs":[]}]}